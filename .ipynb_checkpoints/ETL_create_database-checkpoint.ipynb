{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy since dicts are mutable\n",
    "    alt_titles = {} #create an empty dict to hold all alternative titles keys\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key] # add the key to the alt_titles dict\n",
    "            movie.pop(key) # remove the key from the movie dict\n",
    "    if len(alt_titles)>0:\n",
    "        movie[\"alt_titles\"] = alt_titles\n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "\n",
    "def extract_transform_load(kaggle_file, ratings_file, wiki_file):\n",
    "    # Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(kaggle_file, low_memory=False)\n",
    "    ratings = pd.read_csv(ratings_file)    \n",
    "\n",
    "    # Open and read the Wikipedia data JSON file.\n",
    "    with open(wiki_file, mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)    \n",
    "    \n",
    "    # Write a list comprehension to filter out TV shows.\n",
    "        wiki_movies = [movie for movie in wiki_movies_raw\n",
    "               if ('Director' in movie or 'Directed by' in movie)\n",
    "                   and 'imdb_link' in movie\n",
    "                   and 'No. of episodes' not in movie]    \n",
    "\n",
    "    # Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]    \n",
    "\n",
    "    # Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "\n",
    "    # Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "    try:\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)        \n",
    "    except:\n",
    "        print(\"imdb_id \", imdb_id, \" was not included\")\n",
    "        pass\n",
    "    #  Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]   \n",
    "\n",
    "    # Create a variable that will hold the non-null values from the “Box office” column.\n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    \n",
    "    # Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)    \n",
    "\n",
    "    # Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'   \n",
    "    # Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,|\\.]\\d{3})+(?!/s[m|b]illion)'    \n",
    "\n",
    "    # Add the parse_dollars function.\n",
    "    def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "        if type(s) != str:\n",
    "            return np.nan    \n",
    "        \n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and \" million\"\n",
    "            # use the re.sub(pattern, replacement_string, string) to remove dollar sign, spaces, commas, and letters if req\n",
    "            # \\$|\\s - dollar sign or space\n",
    "            # [a-zA-Z] - any words uppper/lower case - such as million\n",
    "            # substitute the string with a '' blank to delete the $ or word (like 'million' or 'millon'\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "            # convert to float and multiply by a million\n",
    "            value = float(s) * 10**6\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and \" billion\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "            # convert to float and multiply by a billion\n",
    "            value = float(s) * 10**9\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    # this is our form_two\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "            # remove dollar sign and commas\n",
    "            s = re.sub('\\$|,','', s)\n",
    "\n",
    "            # convert to float\n",
    "            value = float(s)\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    # Clean the box office column in the wiki_movies_df DataFrame.\n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    \n",
    "    # Clean the budget column in the wiki_movies_df DataFrame.\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)    \n",
    "\n",
    "    # Clean the release date column in the wiki_movies_df DataFrame.\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'\n",
    "                            \n",
    "    release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)\n",
    "    \n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)                        \n",
    "    \n",
    "\n",
    "    # Clean the running time column in the wiki_movies_df DataFrame.\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)   \n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "    \n",
    "     \n",
    "    # 2. Clean the Kaggle metadata.\n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')\n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "    kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "    kaggle_metadata['id'] = pd.to_numeric(kaggle_metadata['id'], errors='raise')\n",
    "    kaggle_metadata['popularity'] = pd.to_numeric(kaggle_metadata['popularity'], errors='raise')\n",
    "    kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "    # 3. Merged the two DataFrames into the movies DataFrame.\n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "\n",
    "    # 4. Drop unnecessary columns from the merged DataFrame.\n",
    "    movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)\n",
    "\n",
    "    # 5. Add in the function to fill in the missing Kaggle data.\n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "            , axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "\n",
    "        # 6. Call the function in Step 5 with the DataFrame and columns as the arguments.\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "\n",
    "    # 7. Filter the movies DataFrame for specific columns.\n",
    "    movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                           'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                           'genres','original_language','overview','spoken_languages','Country',\n",
    "                           'production_companies','production_countries','Distributor',\n",
    "                           'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                          ]]\n",
    "\n",
    "    # 8. Rename the columns in the movies DataFrame.\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                      'title_kaggle':'title',\n",
    "                      'url':'wikipedia_url',\n",
    "                      'budget_kaggle':'budget',\n",
    "                      'release_date_kaggle':'release_date',\n",
    "                      'Country':'country',\n",
    "                      'Distributor':'distributor',\n",
    "                      'Producer(s)':'producers',\n",
    "                      'Director':'director',\n",
    "                      'Starring':'starring',\n",
    "                      'Cinematography':'cinematography',\n",
    "                      'Editor(s)':'editors',\n",
    "                      'Writer(s)':'writers',\n",
    "                      'Composer(s)':'composers',\n",
    "                      'Based on':'based_on'\n",
    "                     }, axis='columns', inplace=True)\n",
    "\n",
    "    # 9. Transform and merge the ratings DataFrame.\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1) \\\n",
    "                .pivot(index='movieId',columns='rating', values='count')\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "    movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    \n",
    "    db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\"\n",
    "    engine = create_engine(db_string)\n",
    "    movies_df.to_sql(name='movies', con=engine, if_exists='replace')\n",
    "\n",
    "    # create a variable for the number of rows imported\n",
    "    rows_imported = 0\n",
    "    # get the start_time from time.time()\n",
    "    start_time = time.time()\n",
    "    for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "\n",
    "        # print out the range of rows that are being imported\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "        data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "        # increment the number of rows imported by the size of 'data'\n",
    "        rows_imported += len(data)\n",
    "\n",
    "        # add elapsed time to final print out\n",
    "        print(f'Done. {time.time() - start_time} total seconds elapsed')\n",
    "#     return wiki_movies_df, movies_with_ratings_df, movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the path to your file directory and variables for the three files.\n",
    "file_dir = 'C://Users/death/Documents/Development/Movies-ETL/Resources/'\n",
    "# The Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia.movies.json'\n",
    "# The Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# The MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 100000...Done. 7.2905051708221436 total seconds elapsed\n",
      "importing rows 100000 to 200000...Done. 14.568983554840088 total seconds elapsed\n",
      "importing rows 200000 to 300000...Done. 24.224287509918213 total seconds elapsed\n",
      "importing rows 300000 to 400000...Done. 32.10122323036194 total seconds elapsed\n",
      "importing rows 400000 to 500000...Done. 40.06397747993469 total seconds elapsed\n",
      "importing rows 500000 to 600000...Done. 47.70449662208557 total seconds elapsed\n",
      "importing rows 600000 to 700000...Done. 55.181501388549805 total seconds elapsed\n",
      "importing rows 700000 to 800000...Done. 62.840049266815186 total seconds elapsed\n",
      "importing rows 800000 to 900000...Done. 70.22034287452698 total seconds elapsed\n",
      "importing rows 900000 to 1000000...Done. 77.73220252990723 total seconds elapsed\n",
      "importing rows 1000000 to 1100000...Done. 85.27508330345154 total seconds elapsed\n",
      "importing rows 1100000 to 1200000...Done. 92.75705480575562 total seconds elapsed\n",
      "importing rows 1200000 to 1300000...Done. 100.78558421134949 total seconds elapsed\n",
      "importing rows 1300000 to 1400000...Done. 108.51593208312988 total seconds elapsed\n",
      "importing rows 1400000 to 1500000...Done. 115.81634831428528 total seconds elapsed\n",
      "importing rows 1500000 to 1600000...Done. 123.33430290222168 total seconds elapsed\n",
      "importing rows 1600000 to 1700000...Done. 130.97082138061523 total seconds elapsed\n",
      "importing rows 1700000 to 1800000...Done. 138.4638433456421 total seconds elapsed\n",
      "importing rows 1800000 to 1900000...Done. 145.82114243507385 total seconds elapsed\n",
      "importing rows 1900000 to 2000000...Done. 153.45573925971985 total seconds elapsed\n",
      "importing rows 2000000 to 2100000...Done. 160.90776300430298 total seconds elapsed\n",
      "importing rows 2100000 to 2200000...Done. 169.09387111663818 total seconds elapsed\n",
      "importing rows 2200000 to 2300000...Done. 176.43529558181763 total seconds elapsed\n",
      "importing rows 2300000 to 2400000...Done. 183.8015398979187 total seconds elapsed\n",
      "importing rows 2400000 to 2500000...Done. 191.14390397071838 total seconds elapsed\n",
      "importing rows 2500000 to 2600000...Done. 198.56406164169312 total seconds elapsed\n",
      "importing rows 2600000 to 2700000...Done. 205.92138576507568 total seconds elapsed\n",
      "importing rows 2700000 to 2800000...Done. 213.2518346309662 total seconds elapsed\n",
      "importing rows 2800000 to 2900000...Done. 220.9093050956726 total seconds elapsed\n",
      "importing rows 2900000 to 3000000...Done. 229.16029906272888 total seconds elapsed\n",
      "importing rows 3000000 to 3100000...Done. 237.1169879436493 total seconds elapsed\n",
      "importing rows 3100000 to 3200000...Done. 244.61490964889526 total seconds elapsed\n",
      "importing rows 3200000 to 3300000...Done. 251.95731163024902 total seconds elapsed\n",
      "importing rows 3300000 to 3400000...Done. 259.58193612098694 total seconds elapsed\n",
      "importing rows 3400000 to 3500000...Done. 267.1765751838684 total seconds elapsed\n",
      "importing rows 3500000 to 3600000...Done. 274.72339248657227 total seconds elapsed\n",
      "importing rows 3600000 to 3700000...Done. 282.3200886249542 total seconds elapsed\n",
      "importing rows 3700000 to 3800000...Done. 289.9726688861847 total seconds elapsed\n",
      "importing rows 3800000 to 3900000...Done. 298.0261104106903 total seconds elapsed\n",
      "importing rows 3900000 to 4000000...Done. 305.84420228004456 total seconds elapsed\n",
      "importing rows 4000000 to 4100000...Done. 313.3312051296234 total seconds elapsed\n",
      "importing rows 4100000 to 4200000...Done. 320.8550250530243 total seconds elapsed\n",
      "importing rows 4200000 to 4300000...Done. 328.25227761268616 total seconds elapsed\n",
      "importing rows 4300000 to 4400000...Done. 335.7951080799103 total seconds elapsed\n",
      "importing rows 4400000 to 4500000...Done. 343.3190107345581 total seconds elapsed\n",
      "importing rows 4500000 to 4600000...Done. 350.82787132263184 total seconds elapsed\n",
      "importing rows 4600000 to 4700000...Done. 358.28592681884766 total seconds elapsed\n",
      "importing rows 4700000 to 4800000...Done. 366.3493630886078 total seconds elapsed\n",
      "importing rows 4800000 to 4900000...Done. 373.79445242881775 total seconds elapsed\n",
      "importing rows 4900000 to 5000000...Done. 381.2645015716553 total seconds elapsed\n",
      "importing rows 5000000 to 5100000...Done. 388.740483045578 total seconds elapsed\n",
      "importing rows 5100000 to 5200000...Done. 396.2005672454834 total seconds elapsed\n",
      "importing rows 5200000 to 5300000...Done. 403.92688059806824 total seconds elapsed\n",
      "importing rows 5300000 to 5400000...Done. 411.79289197921753 total seconds elapsed\n",
      "importing rows 5400000 to 5500000...Done. 419.6350483894348 total seconds elapsed\n",
      "importing rows 5500000 to 5600000...Done. 427.344509601593 total seconds elapsed\n",
      "importing rows 5600000 to 5700000...Done. 435.79591035842896 total seconds elapsed\n",
      "importing rows 5700000 to 5800000...Done. 443.92915868759155 total seconds elapsed\n",
      "importing rows 5800000 to 5900000...Done. 451.59502363204956 total seconds elapsed\n",
      "importing rows 5900000 to 6000000...Done. 460.1630735397339 total seconds elapsed\n",
      "importing rows 6000000 to 6100000...Done. 471.13243794441223 total seconds elapsed\n",
      "importing rows 6100000 to 6200000...Done. 481.85670804977417 total seconds elapsed\n",
      "importing rows 6200000 to 6300000...Done. 492.5286056995392 total seconds elapsed\n",
      "importing rows 6300000 to 6400000...Done. 504.0171205997467 total seconds elapsed\n",
      "importing rows 6400000 to 6500000...Done. 513.960024356842 total seconds elapsed\n",
      "importing rows 6500000 to 6600000...Done. 524.8505563735962 total seconds elapsed\n",
      "importing rows 6600000 to 6700000...Done. 535.075483083725 total seconds elapsed\n",
      "importing rows 6700000 to 6800000...Done. 545.0686547756195 total seconds elapsed\n",
      "importing rows 6800000 to 6900000...Done. 554.6261434555054 total seconds elapsed\n",
      "importing rows 6900000 to 7000000...Done. 564.3991961479187 total seconds elapsed\n",
      "importing rows 7000000 to 7100000...Done. 574.4456179141998 total seconds elapsed\n",
      "importing rows 7100000 to 7200000...Done. 584.2461528778076 total seconds elapsed\n",
      "importing rows 7200000 to 7300000...Done. 594.9245426654816 total seconds elapsed\n",
      "importing rows 7300000 to 7400000...Done. 605.1675927639008 total seconds elapsed\n",
      "importing rows 7400000 to 7500000...Done. 614.7688202857971 total seconds elapsed\n",
      "importing rows 7500000 to 7600000...Done. 624.8511064052582 total seconds elapsed\n",
      "importing rows 7600000 to 7700000...Done. 635.3981864452362 total seconds elapsed\n",
      "importing rows 7700000 to 7800000...Done. 646.2862455844879 total seconds elapsed\n",
      "importing rows 7800000 to 7900000...Done. 656.8953492641449 total seconds elapsed\n",
      "importing rows 7900000 to 8000000...Done. 667.2364046573639 total seconds elapsed\n",
      "importing rows 8000000 to 8100000...Done. 676.8815438747406 total seconds elapsed\n",
      "importing rows 8100000 to 8200000...Done. 686.5297272205353 total seconds elapsed\n",
      "importing rows 8200000 to 8300000...Done. 696.4448010921478 total seconds elapsed\n",
      "importing rows 8300000 to 8400000...Done. 708.227224111557 total seconds elapsed\n",
      "importing rows 8400000 to 8500000...Done. 718.4905524253845 total seconds elapsed\n",
      "importing rows 8500000 to 8600000...Done. 731.1422176361084 total seconds elapsed\n",
      "importing rows 8600000 to 8700000...Done. 742.8447394371033 total seconds elapsed\n",
      "importing rows 8700000 to 8800000...Done. 754.1207182407379 total seconds elapsed\n",
      "importing rows 8800000 to 8900000...Done. 766.7933802604675 total seconds elapsed\n",
      "importing rows 8900000 to 9000000...Done. 777.5420758724213 total seconds elapsed\n",
      "importing rows 9000000 to 9100000...Done. 787.5345673561096 total seconds elapsed\n",
      "importing rows 9100000 to 9200000...Done. 797.6727728843689 total seconds elapsed\n",
      "importing rows 9200000 to 9300000...Done. 807.9056820869446 total seconds elapsed\n",
      "importing rows 9300000 to 9400000...Done. 821.3262658119202 total seconds elapsed\n",
      "importing rows 9400000 to 9500000...Done. 835.3047788143158 total seconds elapsed\n",
      "importing rows 9500000 to 9600000...Done. 846.6428945064545 total seconds elapsed\n",
      "importing rows 9600000 to 9700000...Done. 858.5988700389862 total seconds elapsed\n",
      "importing rows 9700000 to 9800000...Done. 870.0196216106415 total seconds elapsed\n",
      "importing rows 9800000 to 9900000...Done. 883.7791512012482 total seconds elapsed\n",
      "importing rows 9900000 to 10000000...Done. 899.5892577171326 total seconds elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 10000000 to 10100000...Done. 910.7848074436188 total seconds elapsed\n",
      "importing rows 10100000 to 10200000...Done. 922.1474523544312 total seconds elapsed\n",
      "importing rows 10200000 to 10300000...Done. 933.8633580207825 total seconds elapsed\n",
      "importing rows 10300000 to 10400000...Done. 945.5145161151886 total seconds elapsed\n",
      "importing rows 10400000 to 10500000...Done. 957.6507256031036 total seconds elapsed\n",
      "importing rows 10500000 to 10600000...Done. 969.1404359340668 total seconds elapsed\n",
      "importing rows 10600000 to 10700000...Done. 980.8901035785675 total seconds elapsed\n",
      "importing rows 10700000 to 10800000...Done. 993.6902794837952 total seconds elapsed\n",
      "importing rows 10800000 to 10900000...Done. 1005.167159318924 total seconds elapsed\n",
      "importing rows 10900000 to 11000000...Done. 1016.8333656787872 total seconds elapsed\n",
      "importing rows 11000000 to 11100000...Done. 1031.0404336452484 total seconds elapsed\n",
      "importing rows 11100000 to 11200000...Done. 1043.5130379199982 total seconds elapsed\n",
      "importing rows 11200000 to 11300000...Done. 1056.2649438381195 total seconds elapsed\n",
      "importing rows 11300000 to 11400000...Done. 1069.1655645370483 total seconds elapsed\n",
      "importing rows 11400000 to 11500000...Done. 1080.5908224582672 total seconds elapsed\n",
      "importing rows 11500000 to 11600000...Done. 1092.2056562900543 total seconds elapsed\n",
      "importing rows 11600000 to 11700000...Done. 1104.129276752472 total seconds elapsed\n",
      "importing rows 11700000 to 11800000...Done. 1115.9507961273193 total seconds elapsed\n",
      "importing rows 11800000 to 11900000...Done. 1129.3840832710266 total seconds elapsed\n",
      "importing rows 11900000 to 12000000...Done. 1139.8387563228607 total seconds elapsed\n",
      "importing rows 12000000 to 12100000...Done. 1150.0650987625122 total seconds elapsed\n",
      "importing rows 12100000 to 12200000...Done. 1160.4493708610535 total seconds elapsed\n",
      "importing rows 12200000 to 12300000...Done. 1171.0685467720032 total seconds elapsed\n",
      "importing rows 12300000 to 12400000...Done. 1182.4457643032074 total seconds elapsed\n",
      "importing rows 12400000 to 12500000...Done. 1196.3747437000275 total seconds elapsed\n",
      "importing rows 12500000 to 12600000...Done. 1209.2202987670898 total seconds elapsed\n",
      "importing rows 12600000 to 12700000...Done. 1223.7871055603027 total seconds elapsed\n",
      "importing rows 12700000 to 12800000...Done. 1235.9304928779602 total seconds elapsed\n",
      "importing rows 12800000 to 12900000...Done. 1247.7173352241516 total seconds elapsed\n",
      "importing rows 12900000 to 13000000...Done. 1259.3568427562714 total seconds elapsed\n",
      "importing rows 13000000 to 13100000...Done. 1270.358929157257 total seconds elapsed\n",
      "importing rows 13100000 to 13200000...Done. 1284.503380060196 total seconds elapsed\n",
      "importing rows 13200000 to 13300000...Done. 1299.0729172229767 total seconds elapsed\n",
      "importing rows 13300000 to 13400000...Done. 1310.3198256492615 total seconds elapsed\n",
      "importing rows 13400000 to 13500000...Done. 1320.9087295532227 total seconds elapsed\n",
      "importing rows 13500000 to 13600000...Done. 1332.5377929210663 total seconds elapsed\n",
      "importing rows 13600000 to 13700000...Done. 1347.1687896251678 total seconds elapsed\n",
      "importing rows 13700000 to 13800000...Done. 1359.530825138092 total seconds elapsed\n",
      "importing rows 13800000 to 13900000...Done. 1372.8658821582794 total seconds elapsed\n",
      "importing rows 13900000 to 14000000...Done. 1386.1427376270294 total seconds elapsed\n",
      "importing rows 14000000 to 14100000...Done. 1396.860890865326 total seconds elapsed\n",
      "importing rows 14100000 to 14200000...Done. 1407.2662799358368 total seconds elapsed\n",
      "importing rows 14200000 to 14300000...Done. 1418.219429731369 total seconds elapsed\n",
      "importing rows 14300000 to 14400000...Done. 1430.1576192378998 total seconds elapsed\n",
      "importing rows 14400000 to 14500000...Done. 1442.3319222927094 total seconds elapsed\n",
      "importing rows 14500000 to 14600000...Done. 1453.9846985340118 total seconds elapsed\n",
      "importing rows 14600000 to 14700000...Done. 1465.9491126537323 total seconds elapsed\n",
      "importing rows 14700000 to 14800000...Done. 1478.6652801036835 total seconds elapsed\n",
      "importing rows 14800000 to 14900000...Done. 1491.3326389789581 total seconds elapsed\n",
      "importing rows 14900000 to 15000000...Done. 1504.324935913086 total seconds elapsed\n",
      "importing rows 15000000 to 15100000...Done. 1515.9412829875946 total seconds elapsed\n",
      "importing rows 15100000 to 15200000...Done. 1526.1191852092743 total seconds elapsed\n",
      "importing rows 15200000 to 15300000...Done. 1536.4804420471191 total seconds elapsed\n",
      "importing rows 15300000 to 15400000...Done. 1546.6678953170776 total seconds elapsed\n",
      "importing rows 15400000 to 15500000...Done. 1557.499062538147 total seconds elapsed\n",
      "importing rows 15500000 to 15600000...Done. 1570.9555327892303 total seconds elapsed\n",
      "importing rows 15600000 to 15700000...Done. 1584.670081615448 total seconds elapsed\n",
      "importing rows 15700000 to 15800000...Done. 1596.5539679527283 total seconds elapsed\n",
      "importing rows 15800000 to 15900000...Done. 1607.999341249466 total seconds elapsed\n",
      "importing rows 15900000 to 16000000...Done. 1618.8946702480316 total seconds elapsed\n",
      "importing rows 16000000 to 16100000...Done. 1629.3243129253387 total seconds elapsed\n",
      "importing rows 16100000 to 16200000...Done. 1641.212261915207 total seconds elapsed\n",
      "importing rows 16200000 to 16300000...Done. 1652.6617126464844 total seconds elapsed\n",
      "importing rows 16300000 to 16400000...Done. 1663.836059808731 total seconds elapsed\n",
      "importing rows 16400000 to 16500000...Done. 1676.7291479110718 total seconds elapsed\n",
      "importing rows 16500000 to 16600000...Done. 1688.9922049045563 total seconds elapsed\n",
      "importing rows 16600000 to 16700000...Done. 1702.612545967102 total seconds elapsed\n",
      "importing rows 16700000 to 16800000...Done. 1714.0663242340088 total seconds elapsed\n",
      "importing rows 16800000 to 16900000...Done. 1727.080374956131 total seconds elapsed\n",
      "importing rows 16900000 to 17000000...Done. 1738.4508242607117 total seconds elapsed\n",
      "importing rows 17000000 to 17100000...Done. 1750.4578931331635 total seconds elapsed\n",
      "importing rows 17100000 to 17200000...Done. 1762.6129064559937 total seconds elapsed\n",
      "importing rows 17200000 to 17300000...Done. 1773.9768052101135 total seconds elapsed\n",
      "importing rows 17300000 to 17400000...Done. 1786.5126707553864 total seconds elapsed\n",
      "importing rows 17400000 to 17500000...Done. 1798.5908432006836 total seconds elapsed\n",
      "importing rows 17500000 to 17600000...Done. 1810.082230091095 total seconds elapsed\n",
      "importing rows 17600000 to 17700000...Done. 1820.6388998031616 total seconds elapsed\n",
      "importing rows 17700000 to 17800000...Done. 1830.5084834098816 total seconds elapsed\n",
      "importing rows 17800000 to 17900000...Done. 1841.6681354045868 total seconds elapsed\n",
      "importing rows 17900000 to 18000000...Done. 1852.6199238300323 total seconds elapsed\n",
      "importing rows 18000000 to 18100000...Done. 1863.8230686187744 total seconds elapsed\n",
      "importing rows 18100000 to 18200000...Done. 1874.9675958156586 total seconds elapsed\n",
      "importing rows 18200000 to 18300000...Done. 1885.9241840839386 total seconds elapsed\n",
      "importing rows 18300000 to 18400000...Done. 1896.6150405406952 total seconds elapsed\n",
      "importing rows 18400000 to 18500000...Done. 1908.7943592071533 total seconds elapsed\n",
      "importing rows 18500000 to 18600000...Done. 1921.3336760997772 total seconds elapsed\n",
      "importing rows 18600000 to 18700000...Done. 1934.5301821231842 total seconds elapsed\n",
      "importing rows 18700000 to 18800000...Done. 1947.4673047065735 total seconds elapsed\n",
      "importing rows 18800000 to 18900000...Done. 1959.41161942482 total seconds elapsed\n",
      "importing rows 18900000 to 19000000...Done. 1971.7084112167358 total seconds elapsed\n",
      "importing rows 19000000 to 19100000...Done. 1982.7167584896088 total seconds elapsed\n",
      "importing rows 19100000 to 19200000...Done. 1994.8726630210876 total seconds elapsed\n",
      "importing rows 19200000 to 19300000...Done. 2006.5634353160858 total seconds elapsed\n",
      "importing rows 19300000 to 19400000...Done. 2018.8601067066193 total seconds elapsed\n",
      "importing rows 19400000 to 19500000...Done. 2031.2586901187897 total seconds elapsed\n",
      "importing rows 19500000 to 19600000...Done. 2042.4107863903046 total seconds elapsed\n",
      "importing rows 19600000 to 19700000...Done. 2054.0045568943024 total seconds elapsed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 19700000 to 19800000...Done. 2065.330635547638 total seconds elapsed\n",
      "importing rows 19800000 to 19900000...Done. 2076.713329076767 total seconds elapsed\n",
      "importing rows 19900000 to 20000000...Done. 2088.14595079422 total seconds elapsed\n",
      "importing rows 20000000 to 20100000...Done. 2098.656126022339 total seconds elapsed\n",
      "importing rows 20100000 to 20200000...Done. 2109.6260783672333 total seconds elapsed\n",
      "importing rows 20200000 to 20300000...Done. 2122.7615213394165 total seconds elapsed\n",
      "importing rows 20300000 to 20400000...Done. 2133.91961812973 total seconds elapsed\n",
      "importing rows 20400000 to 20500000...Done. 2145.4173016548157 total seconds elapsed\n",
      "importing rows 20500000 to 20600000...Done. 2155.7921266555786 total seconds elapsed\n",
      "importing rows 20600000 to 20700000...Done. 2166.325073480606 total seconds elapsed\n",
      "importing rows 20700000 to 20800000...Done. 2177.588385820389 total seconds elapsed\n",
      "importing rows 20800000 to 20900000...Done. 2189.436585187912 total seconds elapsed\n",
      "importing rows 20900000 to 21000000...Done. 2200.8517434597015 total seconds elapsed\n",
      "importing rows 21000000 to 21100000...Done. 2213.462314605713 total seconds elapsed\n",
      "importing rows 21100000 to 21200000...Done. 2226.1304755210876 total seconds elapsed\n",
      "importing rows 21200000 to 21300000...Done. 2237.323945760727 total seconds elapsed\n",
      "importing rows 21300000 to 21400000...Done. 2248.1895837783813 total seconds elapsed\n",
      "importing rows 21400000 to 21500000...Done. 2259.417630672455 total seconds elapsed\n",
      "importing rows 21500000 to 21600000...Done. 2271.8849046230316 total seconds elapsed\n",
      "importing rows 21600000 to 21700000...Done. 2283.1777667999268 total seconds elapsed\n",
      "importing rows 21700000 to 21800000...Done. 2294.213249206543 total seconds elapsed\n",
      "importing rows 21800000 to 21900000...Done. 2304.4496824741364 total seconds elapsed\n",
      "importing rows 21900000 to 22000000...Done. 2314.660383939743 total seconds elapsed\n",
      "importing rows 22000000 to 22100000...Done. 2326.713842391968 total seconds elapsed\n",
      "importing rows 22100000 to 22200000...Done. 2337.983409881592 total seconds elapsed\n",
      "importing rows 22200000 to 22300000...Done. 2349.8672111034393 total seconds elapsed\n",
      "importing rows 22300000 to 22400000...Done. 2359.4219887256622 total seconds elapsed\n",
      "importing rows 22400000 to 22500000...Done. 2369.702517747879 total seconds elapsed\n",
      "importing rows 22500000 to 22600000...Done. 2381.3422906398773 total seconds elapsed\n",
      "importing rows 22600000 to 22700000...Done. 2394.787672996521 total seconds elapsed\n",
      "importing rows 22700000 to 22800000...Done. 2406.749068260193 total seconds elapsed\n",
      "importing rows 22800000 to 22900000...Done. 2417.8849244117737 total seconds elapsed\n",
      "importing rows 22900000 to 23000000...Done. 2429.0382585525513 total seconds elapsed\n",
      "importing rows 23000000 to 23100000...Done. 2440.6836948394775 total seconds elapsed\n",
      "importing rows 23100000 to 23200000...Done. 2452.153009414673 total seconds elapsed\n",
      "importing rows 23200000 to 23300000...Done. 2463.5696527957916 total seconds elapsed\n",
      "importing rows 23300000 to 23400000...Done. 2471.936461687088 total seconds elapsed\n",
      "importing rows 23400000 to 23500000...Done. 2479.8862442970276 total seconds elapsed\n",
      "importing rows 23500000 to 23600000...Done. 2487.973646879196 total seconds elapsed\n",
      "importing rows 23600000 to 23700000...Done. 2496.3223247528076 total seconds elapsed\n",
      "importing rows 23700000 to 23800000...Done. 2505.533095598221 total seconds elapsed\n",
      "importing rows 23800000 to 23900000...Done. 2515.3609657287598 total seconds elapsed\n",
      "importing rows 23900000 to 24000000...Done. 2524.106612920761 total seconds elapsed\n",
      "importing rows 24000000 to 24100000...Done. 2532.5450117588043 total seconds elapsed\n",
      "importing rows 24100000 to 24200000...Done. 2540.5197191238403 total seconds elapsed\n",
      "importing rows 24200000 to 24300000...Done. 2548.7297863960266 total seconds elapsed\n",
      "importing rows 24300000 to 24400000...Done. 2556.480060338974 total seconds elapsed\n",
      "importing rows 24400000 to 24500000...Done. 2564.31355881691 total seconds elapsed\n",
      "importing rows 24500000 to 24600000...Done. 2572.3251338005066 total seconds elapsed\n",
      "importing rows 24600000 to 24700000...Done. 2579.8091537952423 total seconds elapsed\n",
      "importing rows 24700000 to 24800000...Done. 2587.3569691181183 total seconds elapsed\n",
      "importing rows 24800000 to 24900000...Done. 2595.027423143387 total seconds elapsed\n",
      "importing rows 24900000 to 25000000...Done. 2602.556346178055 total seconds elapsed\n",
      "importing rows 25000000 to 25100000...Done. 2610.689539670944 total seconds elapsed\n",
      "importing rows 25100000 to 25200000...Done. 2618.442805290222 total seconds elapsed\n",
      "importing rows 25200000 to 25300000...Done. 2626.1421523094177 total seconds elapsed\n",
      "importing rows 25300000 to 25400000...Done. 2633.8836357593536 total seconds elapsed\n",
      "importing rows 25400000 to 25500000...Done. 2642.1278355121613 total seconds elapsed\n",
      "importing rows 25500000 to 25600000...Done. 2650.1913311481476 total seconds elapsed\n",
      "importing rows 25600000 to 25700000...Done. 2658.177137374878 total seconds elapsed\n",
      "importing rows 25700000 to 25800000...Done. 2666.225873708725 total seconds elapsed\n",
      "importing rows 25800000 to 25900000...Done. 2674.160653114319 total seconds elapsed\n",
      "importing rows 25900000 to 26000000...Done. 2682.3935782909393 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Done. 2684.6146388053894 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# 11. Set the three variables equal to the function created in D1.\n",
    "extract_transform_load(kaggle_file, ratings_file, wiki_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
